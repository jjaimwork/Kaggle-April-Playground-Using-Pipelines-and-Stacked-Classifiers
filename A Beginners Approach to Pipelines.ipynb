{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem Definition\n",
    "\n",
    "> Predict whether or not the person survived or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data\n",
    "This data was taken from kaggle's Monthly Tabular Playground  \n",
    "\n",
    ">The dataset is synthetic but based on a real dataset (in this case, the actual Titanic data!) and generated using a CTGAN. The statistical properties of this dataset are very similar to the original Titanic dataset, but there's no way to \"cheat\" by using public labels for predictions. How well does your model perform on truly unseen data?  \n",
    "The data has been split into two groups:  \n",
    "◽ training set (train.csv)  \n",
    "◽ test set (test.csv)  \n",
    "\n",
    "https://www.kaggle.com/c/tabular-playground-series-apr-2021/\n",
    "\n",
    "| Variable | Definition                                 | Key                                            |\n",
    "|----------|--------------------------------------------|------------------------------------------------|\n",
    "| survival | Survival                                   | 0 = No, 1 = Yes                                |\n",
    "| pclass   | Ticket class                               | 1=1st, 2=2nd, 3=3rd                            |\n",
    "| sex      | Sex                                        | 0=Female, 1=Male                               |\n",
    "| Age      | Age in years                               |                                                |\n",
    "| sibsp    | # of siblings / spouses aboard the Titanic |                                                |\n",
    "| parch    | # of parents / children aboard the Titanic |                                                |\n",
    "| ticket   | Ticket number                              |                                                |\n",
    "| fare     | Passenger fare                             |                                                |\n",
    "| cabin    | Cabin number                               |                                                |\n",
    "| embarked | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   PassengerId  100000 non-null  int64  \n",
      " 1   Survived     100000 non-null  int64  \n",
      " 2   Pclass       100000 non-null  int64  \n",
      " 3   Name         100000 non-null  object \n",
      " 4   Sex          100000 non-null  object \n",
      " 5   Age          96708 non-null   float64\n",
      " 6   SibSp        100000 non-null  int64  \n",
      " 7   Parch        100000 non-null  int64  \n",
      " 8   Ticket       95377 non-null   object \n",
      " 9   Fare         99866 non-null   float64\n",
      " 10  Cabin        32134 non-null   object \n",
      " 11  Embarked     99750 non-null   object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oconnor, Frankie</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209245</td>\n",
       "      <td>27.14</td>\n",
       "      <td>C12239</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bryan, Drew</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27323</td>\n",
       "      <td>13.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Owens, Kenneth</td>\n",
       "      <td>male</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 457703</td>\n",
       "      <td>71.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kramer, James</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A. 10866</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Bond, Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427635</td>\n",
       "      <td>7.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass              Name   Sex    Age  SibSp  Parch  \\\n",
       "0            0         1       1  Oconnor, Frankie  male    NaN      2      0   \n",
       "1            1         0       3       Bryan, Drew  male    NaN      0      0   \n",
       "2            2         0       3    Owens, Kenneth  male   0.33      1      2   \n",
       "3            3         0       3     Kramer, James  male  19.00      0      0   \n",
       "4            4         1       3     Bond, Michael  male  25.00      0      0   \n",
       "\n",
       "      Ticket   Fare   Cabin Embarked  \n",
       "0     209245  27.14  C12239        S  \n",
       "1      27323  13.35     NaN        S  \n",
       "2  CA 457703  71.29     NaN        S  \n",
       "3   A. 10866  13.04     NaN        S  \n",
       "4     427635   7.76     NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon looking at the dataset, we can see there are a lot of missing values especially on the Cabin column. We're first going to clean the data and create a new version of the dataset where our machine learning algorithm can have no problem learning at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# dropping the unneeded columns in the dataset\n",
    "unneeded_cols = ['Cabin', 'PassengerId', 'Name', 'Ticket']\n",
    "for col in unneeded_cols:\n",
    "    test_df = test_df.drop([col], axis=1)\n",
    "    train_df = train_df.drop([col], axis=1)\n",
    "    \n",
    "train_df = train_df[train_df['Embarked'].notna()]\n",
    "train_df = train_df[train_df['Fare'].notna()]\n",
    "#test_df = test_df[test_df['Embarked'].notna()]\n",
    "\n",
    "# converting categorical values to numeric    \n",
    "cat_features = ['Pclass','Sex', 'Embarked', 'SibSp', 'Parch']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "# filling missing values\n",
    "num_features = ['Age']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])\n",
    "\n",
    "# preprocess and modeling pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat',categorical_transformer, cat_features),\n",
    "        ('num', numeric_transformer, num_features),\n",
    "    ])\n",
    "\n",
    "\n",
    "# split the target column and features column\n",
    "X = train_df.drop('Survived', axis=1)\n",
    "y = train_df.Survived\n",
    "\n",
    "# split using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:42:26] WARNING: ..\\src\\learner.cc:573: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:42:26] WARNING: ..\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "model_alg = {\n",
    "    'Logistic Regression' : LogisticRegression(solver='liblinear'),\n",
    "    'Ridge Classifier' : RidgeClassifier(),\n",
    "    'SGDClassifier' : SGDClassifier(),\n",
    "    'RandomForest' : RandomForestClassifier(),\n",
    "    'ExtraTreesClassifier' : ExtraTreesClassifier(),\n",
    "    'KNC': KNeighborsClassifier(),\n",
    "    'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
    "    'LGBMClassifier' : LGBMClassifier(verbose=-1),\n",
    "    'XGBClassifier' : XGBClassifier(verbose=0, use_label_encoder=False),\n",
    "    'CatBoostClassifier' : CatBoostClassifier(verbose=0),\n",
    "}\n",
    "\n",
    "score = {}\n",
    "for name, _ in model_alg.items():\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('model', _)])\n",
    "    model.fit(X_train, y_train)\n",
    "    score[name] = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.7662785250619019,\n",
       " 'Ridge Classifier': 0.768955363715452,\n",
       " 'SGDClassifier': 0.7519574382654085,\n",
       " 'RandomForest': 0.7526935688951348,\n",
       " 'ExtraTreesClassifier': 0.7508867028039885,\n",
       " 'KNC': 0.7422204376631198,\n",
       " 'DecisionTreeClassifier': 0.7509870842534966,\n",
       " 'LGBMClassifier': 0.7700260991768721,\n",
       " 'XGBClassifier': 0.7693903499966539,\n",
       " 'CatBoostClassifier': 0.768687679850097}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBMClassifier'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "max(score.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Pclass', 'Sex', 'Embarked',\n",
       "                                                   'SibSp', 'Parch']),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent'))]),\n",
       "                                                  ['Age'])])),\n",
       "                ('model', LGBMClassifier())])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('model', LGBMClassifier())])\n",
    "model.fit(X_test, y_test)\n",
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_grid = {\n",
    "    'model__num_leaves' : [5,10,15],\n",
    "    'model__min_data_in_leaf' : [900,920,940],\n",
    "    'model__max_depth' : [3,5,7],\n",
    "    'model__n_estimators' : [900,920,940]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 5,\n",
       " 'model__min_data_in_leaf': 920,\n",
       " 'model__n_estimators': 900,\n",
       " 'model__num_leaves': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'model__max_depth': 5,\n",
    " 'model__min_data_in_leaf': 920,\n",
    " 'model__n_estimators': 900,\n",
    " 'model__num_leaves': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('cat',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                         ('onehot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['Pclass',\n",
       "                                                                          'Sex',\n",
       "                                                                          'Embarked',\n",
       "                                                                          'SibSp',\n",
       "                                                                          'Parch']),\n",
       "                                                                        ('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent'))]),\n",
       "                                                                         ['Age'])])),\n",
       "                                       ('model', LGBMClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [3, 5, 7],\n",
       "                         'model__min_data_in_leaf': [900, 920, 940],\n",
       "                         'model__n_estimators': [900, 920, 940],\n",
       "                         'model__num_leaves': [5, 10, 15]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model = GridSearchCV(model, \n",
    "                        pipe_grid,\n",
    "                        cv=5,\n",
    "                        verbose=2,\n",
    "                        n_jobs=-1,\n",
    "                       )\n",
    "gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7706953088402596"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write\n",
    "pickle.dump(gs_model, open('gs_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read\n",
    "load_pickle_model_gs = pickle.load(open('gs_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 5,\n",
       " 'model__min_data_in_leaf': 920,\n",
       " 'model__n_estimators': 920,\n",
       " 'model__num_leaves': 15}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_pickle_model_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76639\n"
     ]
    }
   ],
   "source": [
    "y_preds = load_pickle_model_gs.predict(X_test)\n",
    "score = roc_auc_score(y_test, y_preds)\n",
    "print(f'{score:0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = load_pickle_model_gs.predict(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Survived'] = y_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('psuedo_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>199995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>199996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>199997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>199998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>199999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived\n",
       "0           100000         0\n",
       "1           100001         1\n",
       "2           100002         1\n",
       "3           100003         0\n",
       "4           100004         1\n",
       "...            ...       ...\n",
       "99995       199995         1\n",
       "99996       199996         0\n",
       "99997       199997         0\n",
       "99998       199998         1\n",
       "99999       199999         1\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['Survived'] = y_preds\n",
    "submission_df.to_csv('submission_base_models.csv', index = False)\n",
    "pd.read_csv(\"submission_base_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
